{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AVeTsB538qE1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/sample_data/vibration_data.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "X = data[['ROLL_BAD', 'PITCH_BAD']].values\n",
        "y = data[['ROLL_FILTERED', 'PITCH_FILTERED']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y)\n",
        "\n",
        "# Split the data into training, validation, and test sets (60%, 20%, 20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Reshape the data to fit the model (adding a channel dimension)\n",
        "X_train = X_train.reshape(-1, X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(-1, X_val.shape[1], 1)\n",
        "X_test = X_test.reshape(-1, X_test.shape[1], 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(2)  # Output layer with 2 neurons for ROLL_FILTERED and PITCH_FILTERED\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me8i9zHY855t",
        "outputId": "cb049294-8d9d-4e95-eac0-238970e9c710"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "57/57 [==============================] - 1s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "57/57 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "57/57 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "57/57 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "57/57 [==============================] - 0s 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "57/57 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "57/57 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Handle NaN values in predictions by replacing them with zero or a specific value\n",
        "y_pred = np.nan_to_num(y_pred)\n",
        "\n",
        "# Inverse transform the predictions and actual values to their original scale\n",
        "y_pred = scaler_y.inverse_transform(y_pred)\n",
        "y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Evaluate the model in terms of regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
        "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
        "print(f'R-squared (R2): {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5XlKTjH9e54",
        "outputId": "12324a10-9d92-48e9-9901-73b51b77e0e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 4ms/step\n",
            "Mean Squared Error (MSE): 339.3893\n",
            "Mean Absolute Error (MAE): 14.1607\n",
            "R-squared (R2): -0.0032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bins for each dimension separately\n",
        "bins_roll = np.linspace(start=min(y_test[:, 0].min(), y_pred[:, 0].min()), stop=max(y_test[:, 0].max(), y_pred[:, 0].max()), num=10)\n",
        "bins_pitch = np.linspace(start=min(y_test[:, 1].min(), y_pred[:, 1].min()), stop=max(y_test[:, 1].max(), y_pred[:, 1].max()), num=10)\n",
        "\n",
        "# Digitize the actual and predicted values into bins\n",
        "y_test_binned_roll = np.digitize(y_test[:, 0], bins_roll)\n",
        "y_pred_binned_roll = np.digitize(y_pred[:, 0], bins_roll)\n",
        "\n",
        "y_test_binned_pitch = np.digitize(y_test[:, 1], bins_pitch)\n",
        "y_pred_binned_pitch = np.digitize(y_pred[:, 1], bins_pitch)\n",
        "\n",
        "# Evaluate the model in terms of accuracy, precision, recall, and F-Score for ROLL\n",
        "accuracy_roll = accuracy_score(y_test_binned_roll, y_pred_binned_roll)\n",
        "precision_roll = precision_score(y_test_binned_roll, y_pred_binned_roll, average='macro', zero_division=0)\n",
        "recall_roll = recall_score(y_test_binned_roll, y_pred_binned_roll, average='macro')\n",
        "f1_roll = f1_score(y_test_binned_roll, y_pred_binned_roll, average='macro')\n",
        "\n",
        "print(f'ROLL - Accuracy: {accuracy_roll:.4f}')\n",
        "print(f'ROLL - Precision: {precision_roll:.4f}')\n",
        "print(f'ROLL - Recall: {recall_roll:.4f}')\n",
        "print(f'ROLL - F1-Score: {f1_roll:.4f}')\n",
        "\n",
        "# Evaluate the model in terms of accuracy, precision, recall, and F-Score for PITCH\n",
        "accuracy_pitch = accuracy_score(y_test_binned_pitch, y_pred_binned_pitch)\n",
        "precision_pitch = precision_score(y_test_binned_pitch, y_pred_binned_pitch, average='macro', zero_division=0)\n",
        "recall_pitch = recall_score(y_test_binned_pitch, y_pred_binned_pitch, average='macro')\n",
        "f1_pitch = f1_score(y_test_binned_pitch, y_pred_binned_pitch, average='macro')\n",
        "\n",
        "print(f'PITCH - Accuracy: {accuracy_pitch:.4f}')\n",
        "print(f'PITCH - Precision: {precision_pitch:.4f}')\n",
        "print(f'PITCH - Recall: {recall_pitch:.4f}')\n",
        "print(f'PITCH - F1-Score: {f1_pitch:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkfrSyps9htM",
        "outputId": "f4ba8bea-5e42-435f-868f-f6192a625301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROLL - Accuracy: 0.1689\n",
            "ROLL - Precision: 0.0169\n",
            "ROLL - Recall: 0.1000\n",
            "ROLL - F1-Score: 0.0289\n",
            "PITCH - Accuracy: 0.3179\n",
            "PITCH - Precision: 0.0318\n",
            "PITCH - Recall: 0.1000\n",
            "PITCH - F1-Score: 0.0482\n"
          ]
        }
      ]
    }
  ]
}